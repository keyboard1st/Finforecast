import torch
import torch.nn as nn
import math
import time


class RoPEPositionalEncoding(nn.Module):
    """
    Rotary Position Embedding (RoPE)
    åŸºäºè®ºæ–‡: RoFormer: Enhanced Transformer with Rotary Position Embedding
    """
    
    def __init__(self, d_model, max_seq_len=4096):
        super().__init__()
        self.d_model = d_model
        
        # è®¡ç®—é¢‘ç‡
        inv_freq = 1.0 / (10000 ** (torch.arange(0, d_model, 2).float() / d_model))
        self.register_buffer('inv_freq', inv_freq)
    
    def forward(self, x):
        """
        Args:
            x: [batch_size, seq_len, d_model]
        Returns:
            rotated x: [batch_size, seq_len, d_model]
        """
        batch_size, seq_len, d_model = x.size()
        
        # ç”Ÿæˆä½ç½®ç´¢å¼•
        position = torch.arange(seq_len, device=x.device).float()
        
        # è®¡ç®—é¢‘ç‡çŸ©é˜µ [seq_len, d_model//2]
        freqs = torch.outer(position, self.inv_freq)
        
        # ç”Ÿæˆcoså’Œsin [seq_len, d_model//2]
        cos_freqs = freqs.cos()
        sin_freqs = freqs.sin()
        
        # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…batchç»´åº¦ [1, seq_len, d_model//2]
        cos_freqs = cos_freqs.unsqueeze(0)
        sin_freqs = sin_freqs.unsqueeze(0)
        
        # åˆ†ç¦»å¥‡å¶ç»´åº¦
        x_even = x[..., 0::2]  # [batch_size, seq_len, d_model//2]
        x_odd = x[..., 1::2]   # [batch_size, seq_len, d_model//2]
        
        # åº”ç”¨æ—‹è½¬å˜æ¢
        rotated_even = x_even * cos_freqs - x_odd * sin_freqs
        rotated_odd = x_even * sin_freqs + x_odd * cos_freqs
        
        # é‡æ–°ç»„åˆ [batch_size, seq_len, d_model]
        rotated_x = torch.zeros_like(x)
        rotated_x[..., 0::2] = rotated_even
        rotated_x[..., 1::2] = rotated_odd
        
        return rotated_x


class RoPETransformerEncoderLayer(nn.Module):
    """
    é›†æˆRoPEçš„Transformer Encoderå±‚
    è‡ªåŠ¨ç¡®ä¿å› æœæ€§ï¼ˆä¸ä½¿ç”¨æœªæ¥ä¿¡æ¯ï¼‰
    """
    
    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):
        super().__init__()
        
        self.d_model = d_model
        self.nhead = nhead
        self.head_dim = d_model // nhead
        
        assert d_model % nhead == 0, f"d_model ({d_model}) å¿…é¡»èƒ½è¢« nhead ({nhead}) æ•´é™¤"
        
        # Query, Key, Value æŠ•å½±
        self.q_proj = nn.Linear(d_model, d_model)
        self.k_proj = nn.Linear(d_model, d_model)
        self.v_proj = nn.Linear(d_model, d_model)
        self.out_proj = nn.Linear(d_model, d_model)
        
        # RoPEä½ç½®ç¼–ç 
        self.rope = RoPEPositionalEncoding(self.head_dim)
        
        # å‰é¦ˆç½‘ç»œ
        self.feed_forward = nn.Sequential(
            nn.Linear(d_model, dim_feedforward),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(dim_feedforward, d_model),
            nn.Dropout(dropout)
        )
        
        # Layer Normalization
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
    
    def _generate_causal_mask(self, seq_len, device):
        """ç”Ÿæˆå› æœæ©ç ç¡®ä¿ä¸ä½¿ç”¨æœªæ¥ä¿¡æ¯"""
        mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1)
        mask = mask.masked_fill(mask == 1, float('-inf'))
        return mask
    
    def forward(self, x):
        """
        Args:
            x: [batch_size, seq_len, d_model]
        Returns:
            [batch_size, seq_len, d_model]
        """
        batch_size, seq_len, d_model = x.size()
        
        # 1. è‡ªæ³¨æ„åŠ›åˆ†æ”¯
        residual = x
        x = self.norm1(x)
        
        # Linear projections
        q = self.q_proj(x).view(batch_size, seq_len, self.nhead, self.head_dim)
        k = self.k_proj(x).view(batch_size, seq_len, self.nhead, self.head_dim)
        v = self.v_proj(x).view(batch_size, seq_len, self.nhead, self.head_dim)
        
        # åº”ç”¨RoPEåˆ°qå’Œk
        q_rope = torch.zeros_like(q)
        k_rope = torch.zeros_like(k)
        
        for head in range(self.nhead):
            q_rope[:, :, head, :] = self.rope(q[:, :, head, :])
            k_rope[:, :, head, :] = self.rope(k[:, :, head, :])
        
        # é‡å¡‘ä¸º [batch_size, nhead, seq_len, head_dim]
        q_rope = q_rope.transpose(1, 2)
        k_rope = k_rope.transpose(1, 2)
        v = v.transpose(1, 2)
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        scores = torch.matmul(q_rope, k_rope.transpose(-2, -1)) / math.sqrt(self.head_dim)
        
        # åº”ç”¨å› æœæ©ç 
        causal_mask = self._generate_causal_mask(seq_len, x.device)
        scores = scores + causal_mask.unsqueeze(0).unsqueeze(0)
        
        # Softmax
        attn_weights = torch.softmax(scores, dim=-1)
        attn_weights = self.dropout(attn_weights)
        
        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
        attn_output = torch.matmul(attn_weights, v)
        
        # é‡å¡‘å› [batch_size, seq_len, d_model]
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)
        attn_output = self.out_proj(attn_output)
        
        # æ®‹å·®è¿æ¥
        x = residual + self.dropout(attn_output)
        
        # 2. å‰é¦ˆç½‘ç»œåˆ†æ”¯
        residual = x
        x = self.norm2(x)
        ff_output = self.feed_forward(x)
        x = residual + ff_output
        
        return x


class TimeSeriesEncoder(nn.Module):
    """
    åŸºäºRoPEçš„æ—¶åºé¢„æµ‹Encoder
    """
    
    def __init__(self, config):
        super().__init__()
        
        # é…ç½®å‚æ•°
        self.input_dim = config.input_dim
        self.hidden_dim = config.hidden_dim
        self.num_layers = config.num_layers
        self.num_heads = config.num_heads
        self.dropout = config.dropout
        self.output_dim = getattr(config, 'output_dim', 1)
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(self.input_dim, self.hidden_dim)
        
        # RoPE Transformerå±‚
        self.encoder_layers = nn.ModuleList([
            RoPETransformerEncoderLayer(
                d_model=self.hidden_dim,
                nhead=self.num_heads,
                dim_feedforward=4 * self.hidden_dim,
                dropout=self.dropout
            )
            for _ in range(self.num_layers)
        ])
        
        # è¾“å‡ºå±‚
        self.output_projection = nn.Linear(self.hidden_dim, self.output_dim)
        
        # æƒé‡åˆå§‹åŒ–
        self._init_weights()
    
    def _init_weights(self):
        """Xavieråˆå§‹åŒ–"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
    
    def forward(self, x):
        """
        Args:
            x: [batch_size, seq_len, input_dim] è¾“å…¥æ—¶åºæ•°æ®
        
        Returns:
            torch.Tensor: é¢„æµ‹è¾“å‡º
            - å¦‚æœoutput_dim=1: [batch_size] æ¯ä¸ªæ ·æœ¬ä¸€ä¸ªé¢„æµ‹å€¼
            - å¦‚æœoutput_dim>1: [batch_size, output_dim] æ¯ä¸ªæ ·æœ¬å¤šä¸ªé¢„æµ‹å€¼
        """
        batch_size, seq_len, _ = x.size()
        
        # 1. è¾“å…¥æŠ•å½±: [B, T, input_dim] -> [B, T, hidden_dim]
        x = self.input_projection(x)
        
        # 2. é€šè¿‡æ‰€æœ‰RoPE Transformerå±‚
        # æ¯å±‚å†…éƒ¨è‡ªåŠ¨åº”ç”¨RoPEä½ç½®ç¼–ç å’Œå› æœæ©ç 
        for layer in self.encoder_layers:
            x = layer(x)
        
        # 3. å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¡¨ç¤ºç”¨äºé¢„æµ‹
        # [batch_size, seq_len, hidden_dim] -> [batch_size, hidden_dim]
        last_hidden = x[:, -1, :]
        
        # 4. è¾“å‡ºæŠ•å½±
        output = self.output_projection(last_hidden)
        
        # 5. å‹ç¼©æœ€åä¸€ç»´
        output = output.squeeze(-1)  # [batch_size, 1] -> [batch_size]
        
        return output


# å‘åå…¼å®¹æ€§åˆ«å
Encoder = TimeSeriesEncoder

# é…ç½®ç±»  
class EncoderConfig:
    def __init__(self, 
                 input_dim=133,
                 hidden_dim=128, 
                 num_layers=3,
                 num_heads=8,
                 dropout=0.1,
                 output_dim=1,
                 device='cuda:0'):
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.num_heads = num_heads
        self.dropout = dropout
        self.output_dim = output_dim
        self.device = device
        
        # éªŒè¯é…ç½®
        assert hidden_dim % num_heads == 0, f"hidden_dim ({hidden_dim}) å¿…é¡»èƒ½è¢« num_heads ({num_heads}) æ•´é™¤"


if __name__ == '__main__':
    # è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡ç°
    torch.manual_seed(42)
    
    # æµ‹è¯•é…ç½®
    config = EncoderConfig(
        input_dim=133,    # è¾“å…¥ç‰¹å¾ç»´åº¦
        hidden_dim=128,   # éšè—å±‚ç»´åº¦ (å¿…é¡»èƒ½è¢«num_headsæ•´é™¤)
        num_layers=3,     # Transformerå±‚æ•°
        num_heads=8,      # æ³¨æ„åŠ›å¤´æ•°
        dropout=0.1,      # Dropoutç‡
        output_dim=1,
        device='cuda:0'
    )
    
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
    import sys
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    if project_root not in sys.path:
        sys.path.append(project_root)
    from get_data.CCB.CCB_dataloader import get_CCB_TimeSeriesDataloader
    TimeSeries_trainloader, TimeSeries_valiloader, TimeSeries_testloader = get_CCB_TimeSeriesDataloader(
        train_time_period='201901-202312', 
        test_time_period='202401-202504',
        shuffle_time=False,
        window_size=30,
        config=config
    )
    x = next(iter(TimeSeries_trainloader))[0]
    x = torch.nan_to_num(x, nan=0)
    batch_size = x.shape[0]
    seq_len = x.shape[1]
    # batch_size = 32
    # seq_len = 30
    # x = torch.randn(batch_size, seq_len, config.input_dim)
    print(f"æ•°æ®å½¢çŠ¶: {x.shape}")

    model = TimeSeriesEncoder(config).to(config.device)
    model.eval()
    
    print(f"\nğŸ“ˆ å‰å‘ä¼ æ’­æµ‹è¯•:")
    print(f"   - è¾“å…¥å½¢çŠ¶: {x.shape}")
    
    start_time = time.time()
    with torch.no_grad():
        output = model(x.to(config.device))
    end_time = time.time()
    print(f"   - å‰å‘ä¼ æ’­æ—¶é—´: {end_time - start_time:.4f}ç§’")
    
    print(f"   - è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"   - è¾“å‡ºèŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
    print(f"   - è¾“å‡ºç¤ºä¾‹: {output[:5].tolist()}")
    
    # éªŒè¯å½¢çŠ¶
    expected_shape = (batch_size,) if config.output_dim == 1 else (batch_size, config.output_dim)
    assert output.shape == expected_shape, f"è¾“å‡ºå½¢çŠ¶é”™è¯¯! æœŸæœ›: {expected_shape}, å®é™…: {output.shape}"
    
